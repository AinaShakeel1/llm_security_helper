import streamlit as st
import os
import requests
from dotenv import load_dotenv

# -----------------------------
# Load environment variables
# -----------------------------
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

if not GROQ_API_KEY:
    st.error("Please set your GROQ_API_KEY environment variable.")
    st.stop()

OWASP_LLM_2025 = """
LLM01:2025 Prompt Injection
LLM02:2025 Sensitive Information Disclosure
LLM03:2025 Supply Chain
LLM04:2025 Data and Model Poisoning
LLM05:2025 Improper Output Handling
LLM06:2025 Excessive Agency
LLM07:2025 System Prompt Leakage
LLM08:2025 Vector and Embedding Weaknesses
LLM09:2025 Misinformation
LLM10:2025 Unbounded Consumption
"""

# -----------------------------
# Helper function to call Groq LLM API
# -----------------------------
# Add error handling for API calls
def call_groq_model(prompt: str, model: str = "llama-3.3-70b-versatile") -> str:
    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 1500,  # Increase for longer outputs
        "temperature": 0
    }

    try:
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        response.raise_for_status()  # Raises HTTPError for bad status codes
        return response.json()["choices"][0]["message"]["content"]
    except requests.exceptions.RequestException as e:
        return f"‚ùå API Error: {str(e)}"
    except KeyError:
        return "‚ùå Unexpected API response format"
# -----------------------------
# Streamlit UI
# -----------------------------
st.title("üîê LLM Security Helper (Groq API)")

st.info(
    "‚ö†Ô∏è Results are generated by a Large Language Model and should be reviewed "
    "by a security professional before production use."
)

tabs = st.tabs(["üß© Code Vulnerability Analysis", "üìã Spec Vulnerability Analysis"])

# ======================================================
# PART 1 ‚Äî CODE ANALYSIS
# ======================================================
with tabs[0]:
    st.header("Part 1: Analyze Code for Security Vulnerabilities")

    code_input = st.text_area(
        "Paste your code here:",
        height=250,
        placeholder="e.g. SQL queries, API handlers, auth logic..."
    )

    if st.button("Analyze Code", key="code_button"):
        if code_input.strip():
            prompt = f"""
You are an application security expert.

Analyze the following code and identify ONLY security vulnerabilities.

You MUST classify each issue using ONLY the following
OWASP Top 10 for LLM Applications (2025):

{OWASP_LLM_2025}

DO NOT invent new categories.
DO NOT use legacy OWASP Web Top 10 labels.
DO NOT say "closest match".

For each vulnerability, output EXACTLY in this format:

### Vulnerability <number>: <short name>
**Description:**
**OWASP LLM Category:** (must be one of LLM01‚ÄìLLM10 above)
**MITRE ATLAS Mapping:** (tactic or technique name)
**Mitigation:**

Code:
{code_input}
"""
            with st.spinner("Analyzing code security..."):
                result = call_groq_model(prompt)

            st.subheader("Security Analysis Results")

            with st.expander("View Analysis", expanded=True):
                st.markdown(result)

        else:
            st.warning("Please enter some code to analyze.")

# ======================================================
# PART 2 ‚Äî SPEC ANALYSIS
# ======================================================
with tabs[1]:
    st.header("Part 2: Analyze Application Specs for Vulnerabilities")

    specs_input = st.text_area(
        "Enter application specifications:",
        height=250,
        placeholder="Describe system architecture, LLM usage, agents, tools, data flows..."
    )

    if st.button("Analyze Specs", key="specs_button"):
        if specs_input.strip():
            prompt = f"""
You are reviewing a Generative AI / Agentic application design.

Identify potential security vulnerabilities that may arise during
development or deployment.

You MUST map every issue to ONLY the following
OWASP Top 10 for LLM Applications (2025):

{OWASP_LLM_2025}

DO NOT invent categories.
Focus on agent autonomy, tool use, permissions, data access,
prompt handling, and deployment risks.

For each vulnerability, output EXACTLY in this format:

### Vulnerability <number>: <short name>
**Description:**
**OWASP LLM Category:** (must be one of LLM01‚ÄìLLM10 above)
**MITRE ATLAS Mapping:** (tactic or technique)
**Mitigation:**

Application Specifications:
{specs_input}
"""
            with st.spinner("Analyzing application specifications..."):
                result = call_groq_model(prompt)

            st.subheader("Vulnerability Analysis Results")

            with st.expander("View Analysis", expanded=True):
                st.markdown(result)

        else:
            st.warning("Please enter application specifications to analyze.")