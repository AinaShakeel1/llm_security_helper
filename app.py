import streamlit as st
import os
import requests
from dotenv import load_dotenv

# -----------------------------
# Load environment variables
# -----------------------------
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

if not GROQ_API_KEY:
    st.error("Please set your GROQ_API_KEY environment variable.")
    st.stop()

# -----------------------------
# Helper function to call Groq LLM API
# -----------------------------
# Add error handling for API calls
def call_groq_model(prompt: str, model: str = "llama-3.3-70b-versatile") -> str:
    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 1500,  # Increase for longer outputs
        "temperature": 0
    }

    try:
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        response.raise_for_status()  # Raises HTTPError for bad status codes
        return response.json()["choices"][0]["message"]["content"]
    except requests.exceptions.RequestException as e:
        return f"‚ùå API Error: {str(e)}"
    except KeyError:
        return "‚ùå Unexpected API response format"
# -----------------------------
# Streamlit UI
# -----------------------------
st.title("üîê LLM Security Helper (Groq API)")

st.info(
    "‚ö†Ô∏è Results are generated by a Large Language Model and should be reviewed "
    "by a security professional before production use."
)

tabs = st.tabs(["üß© Code Vulnerability Analysis", "üìã Spec Vulnerability Analysis"])

# ======================================================
# PART 1 ‚Äî CODE ANALYSIS
# ======================================================
with tabs[0]:
    st.header("Part 1: Analyze Code for Security Vulnerabilities")

    code_input = st.text_area(
        "Paste your code here:",
        height=250,
        placeholder="e.g. SQL queries, API handlers, auth logic..."
    )

    if st.button("Analyze Code", key="code_button"):
        if code_input.strip():
            prompt = f"""You are a security expert conducting a code security audit.

Analyze the following code ONLY for CRITICAL security vulnerabilities that could lead to:
- Unauthorized access
- Data breaches
- Code injection
- Authentication bypass
- Privilege escalation

IGNORE:
- Performance issues
- Code style
- General best practices that aren't security-critical

For EACH vulnerability found, provide:

### Vulnerability <number>: <name>
**Description:**  
**Exploitation Scenario:**  
**OWASP Top 10 (2021) Mapping:**  
**MITRE ATLAS Mapping:** (if AI/ML related, otherwise write "N/A")  
**Recommended Mitigation:**  
**Example Secure Code:**

If no critical vulnerabilities are found, state: "No critical security vulnerabilities detected."

Code:
```
{code_input}
```
"""
            with st.spinner("Analyzing code security..."):
                result = call_groq_model(prompt)

            st.subheader("Security Analysis Results")

            with st.expander("View Analysis", expanded=True):
                st.markdown(result)

        else:
            st.warning("Please enter some code to analyze.")

# ======================================================
# PART 2 ‚Äî SPEC ANALYSIS
# ======================================================
with tabs[1]:
    st.header("Part 2: Analyze Application Specs for Vulnerabilities")

    specs_input = st.text_area(
        "Enter application specifications:",
        height=250,
        placeholder="Describe system architecture, LLM usage, agents, tools, data flows..."
    )

    if st.button("Analyze Specs", key="specs_button"):
        if specs_input.strip():
            prompt = f"""
You are a security expert reviewing a Generative AI / Agentic application.

Identify potential security vulnerabilities that may arise during
development or deployment.

IMPORTANT:
- Use ONLY standard OWASP Top 10 for LLM Applications categories
  (e.g., Prompt Injection, Insecure Output Handling, Excessive Agency, etc.)
- If unsure, choose the closest match and label it clearly.

For EACH vulnerability, return the output in the following format:

### Vulnerability <number>: <name>
**Description:**  
**How it could be exploited:**  
**OWASP Top 10 for LLM Applications:**  
**MITRE ATLAS Mapping:**  
**Recommended Mitigation:**  

Application Specifications:
{specs_input}
"""

            with st.spinner("Analyzing application specifications..."):
                result = call_groq_model(prompt)

            st.subheader("Vulnerability Analysis Results")

            with st.expander("View Analysis", expanded=True):
                st.markdown(result)

        else:
            st.warning("Please enter application specifications to analyze.")
